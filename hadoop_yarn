# Join
Join Datebase in Date '2018_10_13'

HDFS只是一个存储的结构，他是不具备计算能力的，为了达到工作所需的计算能力，我们就需要在HDFS之中再次搭建一个用以管理运行计算逻辑的平台，这就是YARN；
在云计算的范畴内，yarn属于PAAS层，也就是不同类型的程序提供运行所需的资源，并管理它们的开始与停止。
我们所使用的服务主要分为两种:长时间运行的与点时间运行的。
也就是说服务与工作是不能相互驳斥的。
所以，yarn的设计理念就是可以同时运行长程序与短程序。
相较于HDFS，yarn的结构也大同小异。
yarn的ResourceManager也叫做资源管理器，它负责全局的资源调度与管理。
向HDFS一样，与之对应的为NodeManager负责管理程序运行所需的资源，是个做苦力的。
但是单个作业所需的资源并NodeManager并不知道，每个作业存在一个ApplicationManager，作业的启动停止要求都是AM向NM交互的，AM对NM说，我要吃两碗饭，NM就要立马向RM汇报‘AM他要吃两碗饭’，RM将携带两碗饭的权限交给NM，然后NM把这两碗饭的资源交给AM，AM才能然这个任务开始运行。
这两碗饭就是盛放在一个Container里面，每个任务都会有一个独立的Container,该任务只能使用这个Container内的资源。
在配置集群时，我们习惯性的将namenode与ResourceManager配置在同一台节点上，并且该节点也可以做datanode与NodeManager,这并不矛盾，为了不浪费任何生产力，用户有权要求皇帝（董事长）也去干活。
job与task的区别:
每个任务就是一个job,当任务开始运行计算时,将其拆分为了多个的task,分给多个datanode来完成.
所以:1/job=n/task;
hadoop的核心协议,为RPC,远程调用协议;
该协议可以使某个程序在不知道网络细节的情况下,请求网络中另一台计算机中的某程序的服务,即:计算机A[程序A(RPC)]>>网路>>计算机B[程序B].
所以Hadoop的安全性能并不是很好.但RPC是分布式程序的应用基础.
RPC的设计目的:调用本机的方法/不同语言程序之间的通讯/不了解底层通讯,像本地方法一样调用.
RPC的特点:封装网络的交互/远程调用对象的代理/可配置可扩展/支持容器

yarn中一个应用程序提交的过程:
首先客户端client启动main函数中的runjob()方法,开启这个作业(A);
然后向ResourceManager提交任务请求,RM将这个作业(A)的id与jar包存放路径返还给client客户端内;
client将jar存放路径做前缀,id为后缀存放在HDFS中,作为唯一路径存放该jar包,该数据将在进程结束后自动删除;
client再次将更为详细的jar信息传送给RM的调度器内,然后RM反手就把这个信息下发给某个NodeManager,由NM开启这个作业(A)的MapReduceAppMaster进程,这个进程MR会根据HDFS内储存的jar包的数据量为NM分配任务;
NM会根据HDFS的心跳协议来接受调度器分配的作业任务,然后开启yarnchild(yarn的孩子/误?),我们姑且认为child就是yarn的本身,它根据命令去到HDFS内检索目标任务的资源,然后开启MapTask与ResourceTask,然后map对数据进行逻辑分析计算,经过环形缓冲区传递给Resource,Resource把处理过的数据进行整合,然后返回给client,展示给用户,然后删除掉HDFS内的jar历史.

yarn的实际作用,在提交过程内可以很清晰的看出.他只是负责了唤醒作业进程,然后为处理目标任务的程序提供可供其运行所需的资源(内存与CPU资源),而之后的实际处理程序便是独立在JAR包内的逻辑与MapReduce的框架.
也就是说.YARN=资源调度管理.可以把它看作一个平台(佣兵任务大厅/误?);
